{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "webscraper_hotels_data_123milhas_decolar_v3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "***Webscraper Hotels Data - 123 Milhas / Decolar***\n",
        "\n",
        "*   Data extraction name, price and provider hotels website 123 Milhas\n",
        "*   Data extraction name and price hotels website Decolar\n",
        "*   Rate comparison\n",
        "*   Search details\n"
      ],
      "metadata": {
        "id": "raC7ShPgq2fA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0JymwC9UpE0N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2252a605-4f98-423a-a749-2e53a8f99e62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.2.0-py3-none-any.whl (983 kB)\n",
            "\u001b[K     |████████████████████████████████| 983 kB 11.0 MB/s \n",
            "\u001b[?25hCollecting trio-websocket~=0.9\n",
            "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
            "Collecting trio~=0.17\n",
            "  Downloading trio-0.20.0-py3-none-any.whl (359 kB)\n",
            "\u001b[K     |████████████████████████████████| 359 kB 17.1 MB/s \n",
            "\u001b[?25hCollecting urllib3[secure,socks]~=1.26\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 84.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.10)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (21.4.0)\n",
            "Collecting outcome\n",
            "  Downloading outcome-1.1.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Collecting async-generator>=1.9\n",
            "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Collecting wsproto>=0.14\n",
            "  Downloading wsproto-1.1.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (2022.5.18.1)\n",
            "Collecting cryptography>=1.3.4\n",
            "  Downloading cryptography-37.0.2-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 59.9 MB/s \n",
            "\u001b[?25hCollecting pyOpenSSL>=0.14\n",
            "  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (2.21)\n",
            "Collecting h11<1,>=0.9.0\n",
            "  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 6.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium) (4.2.0)\n",
            "Installing collected packages: sniffio, outcome, h11, cryptography, async-generator, wsproto, urllib3, trio, pyOpenSSL, trio-websocket, selenium\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.9 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed async-generator-1.10 cryptography-37.0.2 h11-0.13.0 outcome-1.1.0 pyOpenSSL-22.0.0 selenium-4.2.0 sniffio-1.2.0 trio-0.20.0 trio-websocket-0.9.2 urllib3-1.26.9 wsproto-1.1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.4-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 14.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.4\n",
            "Get:1 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:4 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:5 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:7 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:9 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:10 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Ign:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:12 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:13 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,992 kB]\n",
            "Get:14 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,021 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,512 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,799 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,286 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,231 kB]\n",
            "Get:19 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.3 kB]\n",
            "Fetched 13.2 MB in 2s (6,348 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n",
            "Suggested packages:\n",
            "  webaccounts-chromium-extension unity-chromium-extension\n",
            "The following NEW packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-chromedriver\n",
            "  chromium-codecs-ffmpeg-extra\n",
            "0 upgraded, 4 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 89.8 MB of archives.\n",
            "After this operation, 302 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 101.0.4951.64-0ubuntu0.18.04.1 [1,142 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 101.0.4951.64-0ubuntu0.18.04.1 [78.5 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 101.0.4951.64-0ubuntu0.18.04.1 [4,980 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 101.0.4951.64-0ubuntu0.18.04.1 [5,153 kB]\n",
            "Fetched 89.8 MB in 1s (70.2 MB/s)\n",
            "Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n",
            "(Reading database ... 155632 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-codecs-ffmpeg-extra_101.0.4951.64-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-codecs-ffmpeg-extra (101.0.4951.64-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser.\n",
            "Preparing to unpack .../chromium-browser_101.0.4951.64-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-browser (101.0.4951.64-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser-l10n.\n",
            "Preparing to unpack .../chromium-browser-l10n_101.0.4951.64-0ubuntu0.18.04.1_all.deb ...\n",
            "Unpacking chromium-browser-l10n (101.0.4951.64-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_101.0.4951.64-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (101.0.4951.64-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-codecs-ffmpeg-extra (101.0.4951.64-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser (101.0.4951.64-0ubuntu0.18.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (101.0.4951.64-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser-l10n (101.0.4951.64-0ubuntu0.18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install selenium\n",
        "!pip install unidecode\n",
        "!apt-get update \n",
        "!apt install chromium-chromedriver"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.common.exceptions import *\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from unidecode import unidecode\n",
        "from time import sleep\n",
        "from datetime import datetime\n",
        "from datetime import date\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "pd.options.mode.chained_assignment = None\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "import gspread\n",
        "gc = gspread.authorize(creds)\n",
        "from gspread_dataframe import set_with_dataframe\n",
        "import gspread_dataframe as gd"
      ],
      "metadata": {
        "id": "-6ZaNfX7rBvH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa506530-0310-4787-dfd1-63cb6725d06c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (3.0.4) doesn't match a supported version!\n",
            "  RequestsDependencyWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chromedriver config\n",
        "\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_experimental_option('excludeSwitches', ['enable-logging'])\n",
        "chrome_options.add_argument('--lang=pt-BR')\n",
        "chrome_options.add_argument('--disable-notifications')\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')"
      ],
      "metadata": {
        "id": "LZ9RjKlw_FU7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rate_fmt(rate):\n",
        "    rate = ' '.join(rate)\n",
        "    rate = rate.strip('R$').lstrip().replace(',','.')\n",
        "    rate = float(rate)\n",
        "    return rate"
      ],
      "metadata": {
        "id": "sIYksbDfaQF7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pax = 2 # Number of guests (adults)"
      ],
      "metadata": {
        "id": "NfBMm-wR_rON"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "destinations = {\n",
        "  'name_destination' : ['Aracaju','Arraial dAjuda','Balneario Camboriu','Belo Horizonte','Brasilia','Buzios','Cabo Frio','Caldas Novas','Campinas','Campos do Jordao','Canela','Curitiba','Florianopolis','Fortaleza','Foz do Iguacu','Gramado','Ilhabela','Ilheus','Joao Pessoa','Maceio','Morro de Sao Paulo','Natal','Porto Alegre','Porto de Galinhas','Porto Seguro','Praia de Pipa','Recife','Rio de Janeiro','Salvador','Sao Paulo'],\n",
        "  'id_destination_123milhas' : ['1010804','1184784','1013062','1017081','1262440','1156720','1027418','1027035','1265185','1621906','1006401','1112002','1001872','1001925','1106867','1006404','1012575','1002846','1111236','1009657','1060292','1009933','1112012','1024069','1262144','1060267','1010394','1010422','1010693','1010502'],\n",
        "  'id_destination_decolar' : ['180','339','192594','701','926','1077','1227','1364','1467','6116','6064','1595','2261','2302','3072','2611','3027','3158','3399','4430','4678','4971','5822','5648','881','5875','6322','6381','7018','6574']\n",
        "}\n",
        "dates = {\n",
        "  'checkin' : ['29-06-2022'],\n",
        "  'checkout' : ['30-06-2022']\n",
        "}"
      ],
      "metadata": {
        "id": "d8kKfbROEXAx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get fee 123 Milhas\n",
        "\n",
        "def get_fee():\n",
        "    global fee\n",
        "    fee = 0\n",
        "\n",
        "    c_dest = 0\n",
        "    c_date = 0\n",
        "\n",
        "    while fee == 0:\n",
        "      try:\n",
        "        driver = webdriver.Chrome(options=chrome_options)\n",
        "        link = f'https://123milhas.com/hoteis?adultos={pax}&bebes=0&checkin={dates[\"checkin\"][c_date]}&checkout={dates[\"checkout\"][c_date]}&criancas=0&id={destinations[\"id_destination_123milhas\"][c_dest]}&localizacao={destinations[\"name_destination\"][c_dest]},%20,%20Brasil&quartos={pax}&tipo=City&search_id='\n",
        "        driver.get(link)\n",
        "        sleep(3)\n",
        "          \n",
        "        price_net_temp = []\n",
        "        tax_temp = []\n",
        "\n",
        "        wait = WebDriverWait(driver, 20)\n",
        "\n",
        "        wait.until(EC.visibility_of_element_located((By.CLASS_NAME, 'image-slider__main-image')))        \n",
        "        hotel1_attributes = driver.find_element(By.XPATH, '/html/body/div[1]/div/hotel-card-price-list-and-filter-wrapper/div/div[3]/div[1]/hotel-list-card[1]/div[2]/div[3]/div[4]/theme-button/button').get_attribute('outerHTML')\n",
        "        attributes_filter1 = ''.join(hotel1_attributes.partition('id')[1:])\n",
        "        attributes_filter2 = attributes_filter1.find('type')\n",
        "        attributes_filter3 = attributes_filter1[:attributes_filter2]\n",
        "        attributes_replacers = attributes_filter3.replace('\"','').replace('=','-').replace(' ','').replace('id-','')\n",
        "        query = \"'#\" + attributes_replacers + \"'\"\n",
        "        \n",
        "        driver.execute_script(f\"document.querySelector({query}).click();\")\n",
        "        new_window = driver.window_handles[1]\n",
        "        driver.switch_to.window(new_window)\n",
        "        \n",
        "        wait.until(EC.visibility_of_element_located((By.CLASS_NAME, 'rooms-details-and-price__button')))\n",
        "        driver.execute_script(\"document.querySelector('#hotel-details-and-info > div > rooms-details-and-price > div > div.rooms-details-and-price__prices-select-holder > theme-button > button').click();\")\n",
        "        \n",
        "        wait.until(EC.visibility_of_element_located((By.CLASS_NAME, 'hotel-checkout-prices-and-tax')))        \n",
        "        price_net_elem = driver.find_element(By.XPATH, '//*[@id=\"checkout-form\"]/div/div[2]/div[1]/hotel-checkout-prices-and-tax/div/div[2]/span[2]')\n",
        "        tax_elem = driver.find_element(By.XPATH, '//*[@id=\"checkout-form\"]/div/div[2]/div[1]/hotel-checkout-prices-and-tax/div/div[3]/span[2]')\n",
        "\n",
        "        price_net_temp.append(price_net_elem.text)\n",
        "        tax_temp.append(tax_elem.text)\n",
        "        price_net = rate_fmt(price_net_temp)\n",
        "        tax = rate_fmt(tax_temp)\n",
        "\n",
        "        calc_fee = tax / price_net\n",
        "        fee = float(\"%.4f\" % calc_fee)        \n",
        "\n",
        "      except:\n",
        "        c_dest += 1\n",
        "\n",
        "    return fee\n",
        "\n",
        "\n",
        "get_fee()\n"
      ],
      "metadata": {
        "id": "zzWex9-Si4kM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8ff1753-f533-4c77-a8a5-ec85ab85a0f6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1446"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scraper\n",
        "\n",
        "class Scraper_123milhas_Decolar:\n",
        "\n",
        "    def scraper(self):\n",
        "        self.data_collect()\n",
        "\n",
        "    def data_collect(self):\n",
        "\n",
        "        c_date = 0\n",
        "        while True:\n",
        "          try:\n",
        "            checkin = dates[\"checkin\"][c_date]\n",
        "            checkout = dates[\"checkout\"][c_date]\n",
        "          \n",
        "            c_dest = 0\n",
        "            while True:\n",
        "              try:\n",
        "                name_destination = destinations[\"name_destination\"][c_dest]\n",
        "                id_destination_123milhas = destinations[\"id_destination_123milhas\"][c_dest]\n",
        "                id_destination_decolar = destinations[\"id_destination_decolar\"][c_dest]\n",
        "\n",
        "                list_name_hotels_123milhas = []\n",
        "                list_price_hotels_123milhas = []\n",
        "                list_channel_hotels_123milhas = []\n",
        "\n",
        "                list_name_hotels_decolar = []\n",
        "                list_price_hotels_decolar = []\n",
        "\n",
        "                # Scraper 123 Milhas\n",
        "                self.list_names = []\n",
        "                self.list_prices = []\n",
        "                self.list_channels = []\n",
        "                self.driver = webdriver.Chrome(options=chrome_options)\n",
        "                self.link = f'https://123milhas.com/hoteis?adultos={pax}&bebes=0&checkin={checkin}&checkout={checkout}&criancas=0&id={id_destination_123milhas}&localizacao={name_destination},%20,%20Brasil&quartos={pax}&tipo=City&search_id='\n",
        "                self.driver.get(self.link)\n",
        "                sleep(3)\n",
        "                wait = WebDriverWait(self.driver, 20)\n",
        "\n",
        "                for p in range(20): # Number of pages to browse (nº > total, run through all)\n",
        "                    item = 1\n",
        "                    wait.until(EC.visibility_of_element_located((By.CLASS_NAME, 'hotel-list-card__total-price')))\n",
        "                    list_length = self.driver.find_elements(By.CLASS_NAME, 'hotel-list-card__total-price')\n",
        "                    list_max = len(list_length)\n",
        "                    for i in range(list_max):\n",
        "                        c = 1\n",
        "                        while c < list_max:\n",
        "                            try:\n",
        "                                names_temp = self.driver.find_elements(By.XPATH,\n",
        "                                    f'//*[@id=\"hotelListHolder\"]/div[3]/div[1]/hotel-list-card[{item}]/div[2]/div[1]/div/h4')\n",
        "                                self.list_names.append(names_temp[0].text)                       \n",
        "                                sleep(1)\n",
        "                                prices_temp = self.driver.find_elements(By.XPATH,\n",
        "                                    f'//*[@id=\"hotelListHolder\"]/div[3]/div[1]/hotel-list-card[{item}]/div[2]/div[2]/div[1]/div/div')\n",
        "                                self.list_prices.append(prices_temp[0].text)          \n",
        "                                sleep(1)\n",
        "                                channels_temp = self.driver.find_element(By.XPATH,\n",
        "                                    f'/html/body/div[1]/div/hotel-card-price-list-and-filter-wrapper/div/div[3]/div[1]/hotel-list-card[{item}]/div[2]/div[1]/image-slider/div/div[1]/img').get_attribute('outerHTML')\n",
        "                                if len(channels_temp) == 0:\n",
        "                                    channels_temp = self.driver.find_element(By.XPATH, f'/html/body/div[1]/div/hotel-card-price-list-and-filter-wrapper/div/div[3]/div[1]/hotel-list-card[{item}]/div[2]/div[2]/image-slider/div/div[1]/img').get_attribute('outerHTML')                        \n",
        "                                if 'omnibees' in channels_temp:\n",
        "                                    self.list_channels.append(1)\n",
        "                                else:\n",
        "                                    self.list_channels.append(0)\n",
        "                                sleep(1)\n",
        "                                item += 1\n",
        "                            except:\n",
        "                                item += 1\n",
        "                                c += 1                        \n",
        "                    try:\n",
        "                      wait.until(EC.visibility_of_element_located((By.CLASS_NAME, 'pagination-next')))\n",
        "                      self.driver.execute_script('document.querySelectorAll(\"#hotelListHolder > div.hotel-card-price-list__cards-holder.hotel-card-price-list__obj-align > div.hotel-card-price-list__pagination-container > ul > li.pagination-next > a\")[0].click();')\n",
        "                      print(f'\\u001b[32m{\"Browsing...\"}\\u001b[0m')\n",
        "                      sleep(3)\n",
        "                    except:\n",
        "                      self.driver.quit()\n",
        "\n",
        "                print('Raw Data:')\n",
        "                print(self.list_names)\n",
        "                print(self.list_prices)\n",
        "                print(self.list_channels)\n",
        "\n",
        "                for name in self.list_names:\n",
        "                    list_name_hotels_123milhas.append(name)\n",
        "                for price in self.list_prices:\n",
        "                    list_price_hotels_123milhas.append(price)  \n",
        "                for channel in self.list_channels:\n",
        "                    list_channel_hotels_123milhas.append(channel)\n",
        "\n",
        "                # Data processing\n",
        "                name_hotels_123m_temp = list(pd.Series(list_name_hotels_123milhas).str.upper())\n",
        "                name_hotels_123m_fmtg = []\n",
        "\n",
        "                for name in name_hotels_123m_temp:\n",
        "                    name_hotels_123m_fmtg.append(unidecode(name))\n",
        "\n",
        "                price_hotels_123m_fmtg = []\n",
        "\n",
        "                for price in list_price_hotels_123milhas:\n",
        "                    for dot in [\".\"]:\n",
        "                        price = price.replace(dot, \"\")\n",
        "                    price_hotels_123m_fmtg.append(price)\n",
        "\n",
        "                price_hotels_123m_fmtg2 = []\n",
        "\n",
        "                for price in price_hotels_123m_fmtg:\n",
        "                    for sign in [\"R$ \"]:\n",
        "                        price = price.replace(sign, \"\")\n",
        "                    price_hotels_123m_fmtg2.append(price)        \n",
        "\n",
        "                price_hotels_123m_fmtg2 = pd.to_numeric(price_hotels_123m_fmtg2, errors='coerce', downcast='unsigned')\n",
        "\n",
        "                data_hotels_123m = []\n",
        "\n",
        "                for elems in zip(name_hotels_123m_fmtg, price_hotels_123m_fmtg2):\n",
        "                    data_hotels_123m.append(elems)\n",
        "                data_hotels_123m_dict = dict(data_hotels_123m)\n",
        "\n",
        "                df_data_hotels_123m = pd.DataFrame(list(data_hotels_123m_dict.items()),\n",
        "                                  columns=['Hotel Name', 'Net Price 123 Milhas'])\n",
        "\n",
        "                length_df1 = len(df_data_hotels_123m)\n",
        "                length_df2 = len(list_channel_hotels_123milhas)\n",
        "                diff_length_dfs = length_df2 - length_df1\n",
        "                list_channel_hotels_123milhas = list_channel_hotels_123milhas[:length_df2 - diff_length_dfs]\n",
        "\n",
        "                df_data_hotels_123m['Total Price 123 Milhas (w/ fee)'] = (df_data_hotels_123m['Net Price 123 Milhas'] * fee) + df_data_hotels_123m['Net Price 123 Milhas'].apply(pd.to_numeric) \n",
        "                df_data_hotels_123m['Total Price 123 Milhas (w/ fee)'] = df_data_hotels_123m['Total Price 123 Milhas (w/ fee)'].astype(int)\n",
        "                df_data_hotels_123m.insert(loc=1, column='Omnibees Provider 123 Milhas', value=list_channel_hotels_123milhas)\n",
        "\n",
        "                # Scraper Decolar\n",
        "                checkin_decolar = datetime.strptime(checkin, \"%d-%m-%Y\").strftime('%Y-%m-%d')\n",
        "                checkout_decolar = datetime.strptime(checkout, \"%d-%m-%Y\").strftime('%Y-%m-%d')\n",
        "\n",
        "                page = 1      \n",
        "                self.driver = webdriver.Chrome(options=chrome_options)\n",
        "                self.link = f'https://www.decolar.com/accommodations/results/CIT_{id_destination_decolar}/{checkin_decolar}/{checkout_decolar}/{pax}?from=SB2&facet=city&searchId=2c403941-a9b6-457f-a17e-5f3131886e89&page={page}'\n",
        "                self.list_names = []\n",
        "                self.list_prices = []\n",
        "                self.driver.get(self.link)\n",
        "                self.driver.find_element(By.XPATH, '//*[@id=\"lgpd-banner\"]/div/a[2]').click()\n",
        "                sleep(3)\n",
        "                \n",
        "                for p in range(20): # Number of pages to browse (nº > total, run through all)\n",
        "                    item = 1\n",
        "                    list_length = self.driver.find_elements(By.CLASS_NAME, 'accommodation-name')\n",
        "                    list_max = len(list_length)\n",
        "                    for i in range(list_max):\n",
        "                        c = 1\n",
        "                        while c < list_max:\n",
        "                            try:\n",
        "                                names_temp = self.driver.find_elements(By.XPATH,\n",
        "                                    f'/html/body/aloha-app-root/aloha-results/div/div/div/div/div[2]/aloha-list-view-container/div[2]/div[{item}]/aloha-cluster-container/div/div/div[1]/div/div[2]/div/aloha-cluster-accommodation-info-container/div[1]/span')\n",
        "                                self.list_names.append(names_temp[0].text)\n",
        "                                sleep(1)\n",
        "                                prices_temp = self.driver.find_elements(By.XPATH,\n",
        "                                    f'/html/body/aloha-app-root/aloha-results/div/div/div/div/div[2]/aloha-list-view-container/div[2]/div[{item}]/aloha-cluster-container/div/div/div[2]/aloha-cluster-pricebox-container/div/div[2]/div[1]/aloha-price-container/aloha-summary-price-test/div/span[2]')\n",
        "                                self.list_prices.append(prices_temp[0].text)          \n",
        "                                sleep(1)\n",
        "                                item += 1\n",
        "                            except:\n",
        "                                item += 1\n",
        "                                c += 1                        \n",
        "                    try:\n",
        "                        page += 1\n",
        "                        self.driver.get(f'https://www.decolar.com/accommodations/results/CIT_{id_destination_decolar}/{checkin_decolar}/{checkout_decolar}/{pax}?from=SB2&facet=city&searchId=2c403941-a9b6-457f-a17e-5f3131886e89&page={page}')\n",
        "                        print(f'\\u001b[32m{\"Browsing...\"}\\u001b[0m')\n",
        "                        sleep(5)\n",
        "                    except:\n",
        "                        self.driver.quit()\n",
        "                \n",
        "                print(\"Raw data:\")\n",
        "                print(self.list_names)\n",
        "                print(self.list_prices)\n",
        "\n",
        "                for name in self.list_names:\n",
        "                    list_name_hotels_decolar.append(name)\n",
        "                for price in self.list_prices:\n",
        "                    list_price_hotels_decolar.append(price)\n",
        "                \n",
        "                # Data processing\n",
        "                name_hotels_desp_temp = list(pd.Series(list_name_hotels_decolar).str.upper())\n",
        "                name_hotels_desp_fmtg = []\n",
        "\n",
        "                for name in name_hotels_desp_temp:\n",
        "                    name_hotels_desp_fmtg.append(unidecode(name))\n",
        "\n",
        "                price_hotels_desp_fmtg = []\n",
        "\n",
        "                for price in list_price_hotels_decolar:\n",
        "                    for dot in [\".\"]:\n",
        "                        price = price.replace(dot, \"\")\n",
        "                    price_hotels_desp_fmtg.append(price)\n",
        "\n",
        "                price_hotels_desp_fmtg = pd.to_numeric(price_hotels_desp_fmtg, errors='coerce', downcast=\"integer\")\n",
        "\n",
        "                data_hotels_desp = []\n",
        "\n",
        "                for elems in zip(name_hotels_desp_fmtg, price_hotels_desp_fmtg):\n",
        "                    data_hotels_desp.append(elems)\n",
        "                data_hotels_desp_dict = dict(data_hotels_desp)\n",
        "                \n",
        "                df_data_hotels_desp = pd.DataFrame(list(data_hotels_desp_dict.items()),\n",
        "                          columns=['Hotel Name', 'Total Price Decolar'])\n",
        "                \n",
        "                # Data merge\n",
        "                data_merge = pd.merge(df_data_hotels_123m, df_data_hotels_desp, on=['Hotel Name'], how='left')\n",
        "                df_rate_comparison = data_merge.dropna()\n",
        "                for prices in df_rate_comparison:\n",
        "                  diff = (df_rate_comparison.loc[:, 'Total Price Decolar'] / df_rate_comparison.loc[:, 'Total Price 123 Milhas (w/ fee)'] -1 ) * 100\n",
        "                  df_rate_comparison.loc[:, 'Variation (total prices)'] = diff\n",
        "                \n",
        "                # Columns additions and transformations \n",
        "                # Name\n",
        "                df_rate_comparison['Hotel Name'] = df_rate_comparison['Hotel Name'].str.title()\n",
        "\n",
        "                # Price Decolar format\n",
        "                df_rate_comparison['Total Price Decolar'] = df_rate_comparison['Total Price Decolar'].astype(int)\n",
        "\n",
        "                # Fee\n",
        "                fee_round = round(fee, 2)\n",
        "                fee_fmtg = str(fee_round).replace('.', ',')\n",
        "                df_rate_comparison['Fee 123 Milhas'] = fee_fmtg\n",
        "                df_rate_comparison.insert(2, 'Fee 123 Milhas', df_rate_comparison.pop('Fee 123 Milhas'))\n",
        "\n",
        "                # BML\n",
        "                df_rate_comparison['BML'] = np.where(df_rate_comparison['Variation (total prices)'] >= 1, 'LOSE', np.where(df_rate_comparison['Variation (total prices)'] <= -1, 'BEAT', 'MEET'))\n",
        "\n",
        "                # Variation\n",
        "                df_rate_comparison['Variation (total prices)'] = round(df_rate_comparison['Variation (total prices)'], 2)\n",
        "                df_rate_comparison['Variation (total prices)'] = df_rate_comparison['Variation (total prices)'].astype(str).str.replace('.',',')\n",
        "\n",
        "                # Extraction Date\n",
        "                current_date = date.today().strftime(\"%d-%m-%Y\")\n",
        "                df_rate_comparison['Extraction Date'] = current_date\n",
        "\n",
        "                date_format = \"%d-%m-%Y\"\n",
        "                cin = datetime.strptime(checkin, date_format)\n",
        "                cout = datetime.strptime(checkout, date_format)\n",
        "                \n",
        "                # ADVP\n",
        "                today = datetime.strptime(current_date, date_format)\n",
        "                delta = cin - today\n",
        "                advp = delta.days\n",
        "                df_rate_comparison['ADVP'] = advp\n",
        "                df_rate_comparison.insert(1, 'ADVP', df_rate_comparison.pop('ADVP'))\n",
        "                \n",
        "                # LOS\n",
        "                delta = cout - cin\n",
        "                los = delta.days\n",
        "                df_rate_comparison['LOS'] = los\n",
        "                df_rate_comparison.insert(1, 'LOS', df_rate_comparison.pop('LOS'))    \n",
        "\n",
        "                # Check-out date\n",
        "                df_rate_comparison['Check-out date'] = checkout\n",
        "                df_rate_comparison.insert(1, 'Check-out date', df_rate_comparison.pop('Check-out date'))\n",
        "                \n",
        "                # Check-in date\n",
        "                df_rate_comparison['Check-in date'] = checkin\n",
        "                df_rate_comparison.insert(1, 'Check-in date', df_rate_comparison.pop('Check-in date'))\n",
        "\n",
        "                # Destination\n",
        "                df_rate_comparison['Destination'] = name_destination\n",
        "                df_rate_comparison.insert(1, 'Destination', df_rate_comparison.pop('Destination'))\n",
        "\n",
        "                # Upload to Google Sheets\n",
        "                ws = gc.open(\"Pricing BR 123 Milhas\").worksheet(\"data\")\n",
        "                ws.add_rows(df_rate_comparison.shape[0])\n",
        "                gd.set_with_dataframe(worksheet=ws, dataframe=df_rate_comparison, include_index=False, include_column_header=False, row=ws.row_count+1, resize=False)\n",
        "\n",
        "                c_dest += 1\n",
        "              except:\n",
        "                c_dest += 1\n",
        "                if c_dest > len(destinations[\"name_destination\"]):\n",
        "                  break\n",
        "            c_date += 1\n",
        "          except:\n",
        "            c_date += 1\n",
        "            if c_date > len(dates[\"checkin\"]):\n",
        "              break                \n",
        "\n",
        "\n",
        "start = Scraper_123milhas_Decolar()\n",
        "start.scraper()\n"
      ],
      "metadata": {
        "id": "KkjSG0_lrkDS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c20dae6-1629-4d5f-e759-080d7254a240"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32mBrowsing...\u001b[0m\n",
            "\u001b[32mBrowsing...\u001b[0m\n",
            "\u001b[32mBrowsing...\u001b[0m\n",
            "\u001b[32mBrowsing...\u001b[0m\n",
            "\u001b[32mBrowsing...\u001b[0m\n",
            "\u001b[32mBrowsing...\u001b[0m\n",
            "\u001b[32mBrowsing...\u001b[0m\n",
            "\u001b[32mBrowsing...\u001b[0m\n",
            "\u001b[32mBrowsing...\u001b[0m\n",
            "\u001b[32mBrowsing...\u001b[0m\n",
            "\u001b[32mBrowsing...\u001b[0m\n",
            "\u001b[32mBrowsing...\u001b[0m\n",
            "\u001b[32mBrowsing...\u001b[0m\n",
            "\u001b[32mBrowsing...\u001b[0m\n",
            "\u001b[32mBrowsing...\u001b[0m\n",
            "\u001b[32mBrowsing...\u001b[0m\n",
            "\u001b[32mBrowsing...\u001b[0m\n",
            "\u001b[32mBrowsing...\u001b[0m\n",
            "\u001b[32mBrowsing...\u001b[0m\n",
            "\u001b[32mBrowsing...\u001b[0m\n",
            "Raw Data:\n",
            "['Simas Praia Hotel', 'Celi Hotel Aracaju', 'Arcus Hotel Aracaju (Ant. Comfort Aracaju)', 'Del Mar Hotel - Aracaju', 'Via Mar Praia Hotel', 'Quality Hotel Aracaju', 'Hotel da Costa By Nobile', 'NB Hotéis', 'Aruanã Eco Praia Hotel', 'Radisson Hotel Aracaju', 'Real Classic Hotel', 'Go Inn Aracaju', 'Hotel Pousada do Sol', 'Farol Plaza Hotel', 'Tropical Mar Hotel', 'Jatobá Praia Hotel', 'Pousada Águas Douradas', 'Del Canto Hotel', 'Pousada Encantare', 'Atalaia Apart Hotel', 'Ibis Aracaju Jardins', 'SAN MANUEL PRAIA HOTEL', 'Hotel Terra do Sol', 'Araras Praia Hotel', 'Ocean Hotel', 'Hotel Algas Marinhas', 'Alto da Praia Hotel', 'Nascimento Praia Hotel', 'Hotel Jangadeiro Aracaju', 'Pousada Sao Luiz - Aracaju', 'Hotel Praia e Mar', 'Hotel Aracaju Express', 'Hotel Mar do Farol', 'Mar do Farol Praia Hotel', 'Araras Praia Hotel', 'Ocean Hotel', 'Hotel Algas Marinhas', 'Alto da Praia Hotel', 'Nascimento Praia Hotel', 'Hotel Jangadeiro Aracaju', 'Pousada Sao Luiz - Aracaju', 'Hotel Praia e Mar', 'Hotel Aracaju Express', 'Hotel Mar do Farol', 'Mar do Farol Praia Hotel', 'Araras Praia Hotel', 'Ocean Hotel', 'Hotel Algas Marinhas', 'Alto da Praia Hotel', 'Nascimento Praia Hotel', 'Hotel Jangadeiro Aracaju', 'Pousada Sao Luiz - Aracaju', 'Hotel Praia e Mar', 'Hotel Aracaju Express', 'Hotel Mar do Farol', 'Mar do Farol Praia Hotel', 'Araras Praia Hotel', 'Ocean Hotel', 'Hotel Algas Marinhas', 'Alto da Praia Hotel', 'Nascimento Praia Hotel', 'Hotel Jangadeiro Aracaju', 'Pousada Sao Luiz - Aracaju', 'Hotel Praia e Mar', 'Hotel Aracaju Express', 'Hotel Mar do Farol', 'Mar do Farol Praia Hotel', 'Araras Praia Hotel', 'Ocean Hotel', 'Hotel Algas Marinhas', 'Alto da Praia Hotel', 'Nascimento Praia Hotel', 'Hotel Jangadeiro Aracaju', 'Pousada Sao Luiz - Aracaju', 'Hotel Praia e Mar', 'Hotel Aracaju Express', 'Hotel Mar do Farol', 'Mar do Farol Praia Hotel', 'Araras Praia Hotel', 'Ocean Hotel', 'Hotel Algas Marinhas', 'Alto da Praia Hotel', 'Nascimento Praia Hotel', 'Hotel Jangadeiro Aracaju', 'Pousada Sao Luiz - Aracaju', 'Hotel Praia e Mar', 'Hotel Aracaju Express', 'Hotel Mar do Farol', 'Mar do Farol Praia Hotel', 'Araras Praia Hotel', 'Ocean Hotel', 'Hotel Algas Marinhas', 'Alto da Praia Hotel', 'Nascimento Praia Hotel', 'Hotel Jangadeiro Aracaju', 'Pousada Sao Luiz - Aracaju', 'Hotel Praia e Mar', 'Hotel Aracaju Express', 'Hotel Mar do Farol', 'Mar do Farol Praia Hotel', 'Araras Praia Hotel', 'Ocean Hotel', 'Hotel Algas Marinhas', 'Alto da Praia Hotel', 'Nascimento Praia Hotel', 'Hotel Jangadeiro Aracaju', 'Pousada Sao Luiz - Aracaju', 'Hotel Praia e Mar', 'Hotel Aracaju Express', 'Hotel Mar do Farol', 'Mar do Farol Praia Hotel', 'Araras Praia Hotel', 'Ocean Hotel', 'Hotel Algas Marinhas', 'Alto da Praia Hotel', 'Nascimento Praia Hotel', 'Hotel Jangadeiro Aracaju', 'Pousada Sao Luiz - Aracaju', 'Hotel Praia e Mar', 'Hotel Aracaju Express', 'Hotel Mar do Farol', 'Mar do Farol Praia Hotel', 'Araras Praia Hotel', 'Ocean Hotel', 'Hotel Algas Marinhas', 'Alto da Praia Hotel', 'Nascimento Praia Hotel', 'Hotel Jangadeiro Aracaju', 'Pousada Sao Luiz - Aracaju', 'Hotel Praia e Mar', 'Hotel Aracaju Express', 'Hotel Mar do Farol', 'Mar do Farol Praia Hotel', 'Araras Praia Hotel', 'Ocean Hotel', 'Hotel Algas Marinhas', 'Alto da Praia Hotel', 'Nascimento Praia Hotel', 'Hotel Jangadeiro Aracaju', 'Pousada Sao Luiz - Aracaju', 'Hotel Praia e Mar', 'Hotel Aracaju Express', 'Hotel Mar do Farol', 'Mar do Farol Praia Hotel', 'Araras Praia Hotel', 'Ocean Hotel', 'Hotel Algas Marinhas', 'Alto da Praia Hotel', 'Nascimento Praia Hotel', 'Hotel Jangadeiro Aracaju', 'Pousada Sao Luiz - Aracaju', 'Hotel Praia e Mar', 'Hotel Aracaju Express', 'Hotel Mar do Farol', 'Mar do Farol Praia Hotel', 'Araras Praia Hotel', 'Ocean Hotel', 'Hotel Algas Marinhas', 'Alto da Praia Hotel', 'Nascimento Praia Hotel', 'Hotel Jangadeiro Aracaju', 'Pousada Sao Luiz - Aracaju', 'Hotel Praia e Mar', 'Hotel Aracaju Express', 'Hotel Mar do Farol', 'Mar do Farol Praia Hotel', 'Araras Praia Hotel', 'Ocean Hotel', 'Hotel Algas Marinhas', 'Alto da Praia Hotel', 'Nascimento Praia Hotel', 'Hotel Jangadeiro Aracaju', 'Pousada Sao Luiz - Aracaju', 'Hotel Praia e Mar', 'Hotel Aracaju Express', 'Hotel Mar do Farol', 'Mar do Farol Praia Hotel', 'Araras Praia Hotel', 'Ocean Hotel', 'Hotel Algas Marinhas', 'Alto da Praia Hotel', 'Nascimento Praia Hotel', 'Hotel Jangadeiro Aracaju', 'Pousada Sao Luiz - Aracaju', 'Hotel Praia e Mar', 'Hotel Aracaju Express', 'Hotel Mar do Farol', 'Mar do Farol Praia Hotel', 'Araras Praia Hotel', 'Ocean Hotel', 'Hotel Algas Marinhas', 'Alto da Praia Hotel', 'Nascimento Praia Hotel', 'Hotel Jangadeiro Aracaju', 'Pousada Sao Luiz - Aracaju', 'Hotel Praia e Mar', 'Hotel Aracaju Express', 'Hotel Mar do Farol', 'Mar do Farol Praia Hotel', 'Araras Praia Hotel', 'Ocean Hotel', 'Hotel Algas Marinhas', 'Alto da Praia Hotel', 'Nascimento Praia Hotel', 'Hotel Jangadeiro Aracaju', 'Pousada Sao Luiz - Aracaju', 'Hotel Praia e Mar', 'Hotel Aracaju Express', 'Hotel Mar do Farol', 'Mar do Farol Praia Hotel', 'Araras Praia Hotel', 'Ocean Hotel', 'Hotel Algas Marinhas', 'Alto da Praia Hotel', 'Nascimento Praia Hotel', 'Hotel Jangadeiro Aracaju', 'Pousada Sao Luiz - Aracaju', 'Hotel Praia e Mar', 'Hotel Aracaju Express', 'Hotel Mar do Farol', 'Mar do Farol Praia Hotel', 'Araras Praia Hotel', 'Ocean Hotel', 'Hotel Algas Marinhas', 'Alto da Praia Hotel', 'Nascimento Praia Hotel', 'Hotel Jangadeiro Aracaju', 'Pousada Sao Luiz - Aracaju', 'Hotel Praia e Mar', 'Hotel Aracaju Express', 'Hotel Mar do Farol', 'Mar do Farol Praia Hotel']\n",
            "['R$ 148', 'R$ 241', 'R$ 161', 'R$ 238', 'R$ 124', 'R$ 192', 'R$ 290', 'R$ 153', 'R$ 259', 'R$ 550', 'R$ 250', 'R$ 161', 'R$ 167', 'R$ 168', 'R$ 153', 'R$ 158', 'R$ 93', 'R$ 143', 'R$ 127', 'R$ 137', 'R$ 146', 'R$ 140', 'R$ 150', 'R$ 115', 'R$ 111', 'R$ 147', 'R$ 107', 'R$ 218', 'R$ 143', 'R$ 196', 'R$ 172', 'R$ 110', 'R$ 88', 'R$ 113', 'R$ 115', 'R$ 111', 'R$ 147', 'R$ 107', 'R$ 218', 'R$ 143', 'R$ 196', 'R$ 172', 'R$ 110', 'R$ 88', 'R$ 113', 'R$ 115', 'R$ 111', 'R$ 147', 'R$ 107', 'R$ 218', 'R$ 143', 'R$ 196', 'R$ 172', 'R$ 110', 'R$ 88', 'R$ 113', 'R$ 115', 'R$ 111', 'R$ 147', 'R$ 107', 'R$ 218', 'R$ 143', 'R$ 196', 'R$ 172', 'R$ 110', 'R$ 88', 'R$ 113', 'R$ 115', 'R$ 111', 'R$ 147', 'R$ 107', 'R$ 218', 'R$ 143', 'R$ 196', 'R$ 172', 'R$ 110', 'R$ 88', 'R$ 113', 'R$ 115', 'R$ 111', 'R$ 147', 'R$ 107', 'R$ 218', 'R$ 143', 'R$ 196', 'R$ 172', 'R$ 110', 'R$ 88', 'R$ 113', 'R$ 115', 'R$ 111', 'R$ 147', 'R$ 107', 'R$ 218', 'R$ 143', 'R$ 196', 'R$ 172', 'R$ 110', 'R$ 88', 'R$ 113', 'R$ 115', 'R$ 111', 'R$ 147', 'R$ 107', 'R$ 218', 'R$ 143', 'R$ 196', 'R$ 172', 'R$ 110', 'R$ 88', 'R$ 113', 'R$ 115', 'R$ 111', 'R$ 147', 'R$ 107', 'R$ 218', 'R$ 143', 'R$ 196', 'R$ 172', 'R$ 110', 'R$ 88', 'R$ 113', 'R$ 115', 'R$ 111', 'R$ 147', 'R$ 107', 'R$ 218', 'R$ 143', 'R$ 196', 'R$ 172', 'R$ 110', 'R$ 88', 'R$ 113', 'R$ 115', 'R$ 111', 'R$ 147', 'R$ 107', 'R$ 218', 'R$ 143', 'R$ 196', 'R$ 172', 'R$ 110', 'R$ 88', 'R$ 113', 'R$ 115', 'R$ 111', 'R$ 147', 'R$ 107', 'R$ 218', 'R$ 143', 'R$ 196', 'R$ 172', 'R$ 110', 'R$ 88', 'R$ 113', 'R$ 115', 'R$ 111', 'R$ 147', 'R$ 107', 'R$ 218', 'R$ 143', 'R$ 196', 'R$ 172', 'R$ 110', 'R$ 88', 'R$ 113', 'R$ 115', 'R$ 111', 'R$ 147', 'R$ 107', 'R$ 218', 'R$ 143', 'R$ 196', 'R$ 172', 'R$ 110', 'R$ 88', 'R$ 113', 'R$ 115', 'R$ 111', 'R$ 147', 'R$ 107', 'R$ 218', 'R$ 143', 'R$ 196', 'R$ 172', 'R$ 110', 'R$ 88', 'R$ 113', 'R$ 115', 'R$ 111', 'R$ 147', 'R$ 107', 'R$ 218', 'R$ 143', 'R$ 196', 'R$ 172', 'R$ 110', 'R$ 88', 'R$ 113', 'R$ 115', 'R$ 111', 'R$ 147', 'R$ 107', 'R$ 218', 'R$ 143', 'R$ 196', 'R$ 172', 'R$ 110', 'R$ 88', 'R$ 113', 'R$ 115', 'R$ 111', 'R$ 147', 'R$ 107', 'R$ 218', 'R$ 143', 'R$ 196', 'R$ 172', 'R$ 110', 'R$ 88', 'R$ 113', 'R$ 115', 'R$ 111', 'R$ 147', 'R$ 107', 'R$ 218', 'R$ 143', 'R$ 196', 'R$ 172', 'R$ 110', 'R$ 88', 'R$ 113']\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0]\n",
            "\u001b[32mBrowsing...\u001b[0m\n",
            "\u001b[32mBrowsing...\u001b[0m\n",
            "\u001b[32mBrowsing...\u001b[0m\n",
            "\u001b[32mBrowsing...\u001b[0m\n",
            "\u001b[32mBrowsing...\u001b[0m\n",
            "\u001b[32mBrowsing...\u001b[0m\n",
            "\u001b[32mBrowsing...\u001b[0m\n",
            "\u001b[32mBrowsing...\u001b[0m\n",
            "\u001b[32mBrowsing...\u001b[0m\n",
            "\u001b[32mBrowsing...\u001b[0m\n",
            "\u001b[32mBrowsing...\u001b[0m\n",
            "\u001b[32mBrowsing...\u001b[0m\n",
            "\u001b[32mBrowsing...\u001b[0m\n",
            "\u001b[32mBrowsing...\u001b[0m\n",
            "\u001b[32mBrowsing...\u001b[0m\n",
            "\u001b[32mBrowsing...\u001b[0m\n",
            "\u001b[32mBrowsing...\u001b[0m\n",
            "\u001b[32mBrowsing...\u001b[0m\n",
            "\u001b[32mBrowsing...\u001b[0m\n",
            "\u001b[32mBrowsing...\u001b[0m\n",
            "Raw data:\n",
            "['Quality Hotel Aracaju', 'Del Mar Hotel', 'Simas Praia Hotel', 'Arcus Hotel Aracaju - antigo Comfort Aracaju', 'Go Inn Hotel Aracaju', 'Vidam Hotel Aracaju', 'Via Mar Praia Hotel', 'Aruanã Eco Praia Hotel', 'San Manuel Praia Hotel', 'Celi Hotel Aracaju', 'NB Hotéis', 'Pousada Raio de Sol', 'Hotel Ibis Budget Aracaju', 'Hotel da Costa By Nobile', 'Aquários Praia Hotel', 'Del Canto Hotel', 'Jatobá Praia Hotel', 'Farol Plaza Hotel', 'Hotel Algas Marinhas', 'Pousada Encantare', 'Vila Aju - Pousada Temática', 'Hotel Pousada do Sol', 'Real Classic Hotel', 'Nascimento Praia Hotel', 'Beira Mar Hotel', 'Hotel Terra do Sol', 'Atalaia Apart Hotel', 'Hotel Praia e Mar', 'Araras Praia Hotel', 'Hotel Aracaju Express', 'Pousada São Luiz', 'Alto Da Praia Aracaju', 'Transcar Suítes', 'Pousada Santa Fé', 'Pousada Olá', 'Terra bahia']\n",
            "['278', '296', '228', '236', '242', '794', '188', '412', '290', '348', '222', '164', '166', '418', '372', '206', '228', '222', '182', '194', '152', '236', '400', '232', '154', '212', '170', '178', '168', '130', '204', '156', '288', '182', '182', '1.050']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:231: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32mBrowsing...\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}